{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import init\n",
    "import warnings\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "def number_of_features_per_level(init_channel_number, num_levels):\n",
    "    \"\"\"Return a list of features, doubling in size depending on the num_levels.\n",
    "    Args:\n",
    "        init_channel_number (int): initial channel number\n",
    "        num_levels (int): number of levels of the deep network\n",
    "    Returns:\n",
    "        list of features (lists)\n",
    "    eg. number_of_features_per_level(64,4) -> [64,128,256,512]\n",
    "    \"\"\"\n",
    "    return [init_channel_number * 2 ** k for k in range(num_levels)]\n",
    "\n",
    "class SELayer(nn.Module):#se+res\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        out=x * y.expand_as(x)+x\n",
    "        out=self.relu(out)\n",
    "        return out\n",
    "class SingleConv(nn.Module):\n",
    "    # Convolution + Batch Norm + ReLU\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, stride=1, num_groups=8, activation=True):\n",
    "        super(SingleConv, self).__init__()\n",
    "\n",
    "        if out_channels < num_groups:\n",
    "            num_groups = 1\n",
    "\n",
    "        if activation:\n",
    "            # use only one group if the given number of groups is greater than the number of channels\n",
    "            self.singleconv = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=False),\n",
    "                nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "                nn.ELU(inplace=True)\n",
    "            )\n",
    "        else:\n",
    "            self.singleconv = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding,stride=stride, bias=False),\n",
    "                nn.GroupNorm(num_groups=num_groups, num_channels=out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.singleconv(x)\n",
    "\n",
    "\n",
    "class Downsampling(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Downsampling, self).__init__()\n",
    "\n",
    "        self.conv1 = SingleConv(in_channels, out_channels, 1, padding=0, stride=2)\n",
    "        self.conv2 = SingleConv(in_channels, out_channels, 3, padding=1, stride=2)\n",
    "        self.conv3 = SingleConv(in_channels, out_channels, 5, padding=2, stride=2)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        down1 = self.conv1(x) + self.conv2(x) + self.conv3(x)\n",
    "        # down2 = self.conv1(down1) + self.conv2(down1) + self.conv3(down1)\n",
    "\n",
    "        return down1\n",
    "        \n",
    "\n",
    "class AttBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttBlock,self).__init__()\n",
    "        self.W_g = SingleConv(F_g, F_int, kernel_size=1, padding=0, activation=False)\n",
    "        \n",
    "        self.W_x = SingleConv(F_l, F_int, kernel_size=1, padding=0, activation=False)\n",
    "\n",
    "        self.psi = SingleConv(F_int, 1, kernel_size=1, padding=0, activation=False)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,g,x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "        psi = self.sigmoid(psi)\n",
    "\n",
    "        return x*psi\n",
    "\n",
    "\n",
    "\n",
    "class RRCU(nn.Module):\n",
    "    # Recurrent Residual Convolutional Unit\n",
    "\n",
    "    def __init__(self, out_channels, t=2, kernel_size=3, **kwargs):\n",
    "        super(RRCU, self).__init__()\n",
    "\n",
    "        self.t = t\n",
    "\n",
    "        self.conv = SingleConv(out_channels, out_channels, kernel_size=kernel_size)\n",
    "    def forward(self,x):\n",
    "\n",
    "        for i in range(self.t):\n",
    "            if i == 0:\n",
    "                x1 = self.conv(x) \n",
    "            x1 = self.conv(x1)\n",
    "\n",
    "        return x1\n",
    "\n",
    "\n",
    "\n",
    "class RRConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels ,t=2, kernel_size=3):\n",
    "        super(RRConvBlock,self).__init__()\n",
    "        #self.se=SELayer(in_channels)\n",
    "        self.module = nn.Sequential(\n",
    "            RRCU(out_channels=out_channels,t=t, kernel_size=kernel_size),\n",
    "            SELayer(out_channels),\n",
    "            RRCU(out_channels=out_channels,t=t, kernel_size=kernel_size),\n",
    "            SELayer(out_channels)\n",
    "        )\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.Conv_1x1(x)\n",
    "        x1 = self.module(x)\n",
    "\n",
    "        return x+x1\n",
    "\n",
    "\n",
    "\n",
    "class Encode(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels ,t=2, conv_kernel_size=3, pool_kernel_size=(1,2,2), pooling=True,attention=True):\n",
    "        super(Encode,self).__init__()\n",
    "        self.attention=attention\n",
    "        self.pooling = pooling\n",
    "        if pooling:\n",
    "            self.maxpool = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
    "\n",
    "        self.module = RRConvBlock(in_channels=in_channels, out_channels=out_channels, t=t, kernel_size=conv_kernel_size)\n",
    "        self.se=SELayer(in_channels)\n",
    "    def forward(self,x):\n",
    "        if self.attention:\n",
    "            pass\n",
    "        if self.pooling:\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.module(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Decode(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(1, 2, 2),padding=1, mode=\"nearest\", **kwargs):\n",
    "        super(Decode, self).__init__()\n",
    "\n",
    "        # self.upsample = InterpolateUpsampling(mode)\n",
    "        self.upconv = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=scale_factor,mode=mode),\n",
    "            SingleConv(in_channels, out_channels, kernel_size=conv_kernel_size, padding=padding)\n",
    "        )\n",
    "        \n",
    "        self.att = AttBlock(out_channels, out_channels, out_channels//2)\n",
    "        self.module = RRConvBlock(in_channels=out_channels, out_channels=out_channels, t=2, kernel_size=conv_kernel_size)\n",
    "\n",
    "    \n",
    "    def forward(self, encoder_features, x):\n",
    "\n",
    "        upx = self.upconv(x)\n",
    "        x = self.att(upx ,encoder_features)\n",
    "\n",
    "       # Summation joining instead of concatenate\n",
    "        x = encoder_features + x\n",
    "\n",
    "        x = self.module(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class R2AttUNet3D(pl.LightningModule):  \n",
    "    \"\"\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`\n",
    "    Based on the implementation of https://github.com/tbuikr/3D-SkipDenseSeg\n",
    "    Paper here : https://arxiv.org/pdf/1709.03199.pdf\n",
    "    Args:\n",
    "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config (list of 4 ints) - how many layers in each pooling block\n",
    "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "          (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate (float) - dropout rate after each dense layer\n",
    "        classes (int) - number of classification classes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                in_channels, \n",
    "                out_channels,  \n",
    "                f_maps = [64,128,256,512],\n",
    "                testing=False,\n",
    "                batch_size=2,\n",
    "                lr=5e-4,\n",
    "                **kwargs):\n",
    "        super(R2AttUNet3D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        if isinstance(f_maps, int):\n",
    "            f_maps = number_of_features_per_level(f_maps, num_levels=4)\n",
    "\n",
    "        assert isinstance(f_maps, list) or isinstance(f_maps, tuple)\n",
    "        assert len(f_maps) > 1, \"Required at least 2 levels in the U-Net\"\n",
    "\n",
    "        self.testing = testing\n",
    "        self.final_activation = nn.Sigmoid()\n",
    "\n",
    "        self.first_conv = Encode(in_channels, in_channels, pooling=False)\n",
    "\n",
    "        self.downsample = Downsampling(in_channels, in_channels)\n",
    "\n",
    "        self.down1 = Encode(in_channels, f_maps[0], pooling=False)\n",
    "        self.down2 = Encode(f_maps[0], f_maps[1])\n",
    "        self.down3 = Encode(f_maps[1], f_maps[2])\n",
    "        self.down4 = Encode(f_maps[2], f_maps[3])\n",
    "        \n",
    "        self.up1 = Decode(f_maps[3], f_maps[2])\n",
    "        self.up2 = Decode(f_maps[2], f_maps[1])\n",
    "        self.up3 = Decode(f_maps[1], f_maps[0])\n",
    "\n",
    "        self.upsample = nn.ConvTranspose3d(f_maps[0], out_channels, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.final_conv = nn.Conv3d(in_channels, out_channels, 1)\n",
    "   \n",
    "        self.num_batch = batch_size\n",
    "        self.epoch = 0\n",
    "        self.lr=lr\n",
    "        self.history={\"loss\":[],\"acc\":[],\"val_loss\":[],\"val_acc\":[],\"iou\":[],\"val_iou\":[]}\n",
    "        self.save_hyperparameters()        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        x1 = self.first_conv(x)\n",
    "        # print(x1.shape)\n",
    "\n",
    "        x = self.downsample(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x2 = self.down1(x)\n",
    "        # print(x2.shape)\n",
    "\n",
    "        x3 = self.down2(x2)\n",
    "        # print(x3.shape)\n",
    "\n",
    "        x4 = self.down3(x3)\n",
    "        # print(x4.shape)\n",
    "\n",
    "        x5 = self.down4(x4)\n",
    "        # print(x5.shape)\n",
    "\n",
    "\n",
    "        x = self.up1(x4, x5)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.up2(x3, x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.up3(x2, x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.upsample(x, x1.size()[2:])\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = x1 + x   \n",
    "\n",
    "        y = self.final_conv(x)\n",
    "        # print(y.shape)\n",
    "\n",
    "        # apply final_activation (i.e. Sigmoid or Softmax) only during prediction. During training the network outputs\n",
    "        if self.testing:\n",
    "            y = self.final_activation(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(model.parameters(), lr=self.lr,eps=1e-4)\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\n",
    "        #scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "        #return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = self.data_augment(inputs, labels, num_batch=self.num_batch)\n",
    "        outputs = self(inputs)\n",
    "        #loss=focal_tversky_loss(outputs,labels)\n",
    "        loss1 = self.calc_loss(labels, outputs)\n",
    "        loss2=GDiceloss(outputs,labels)\n",
    "        loss=loss2\n",
    "        #loss=Diceloss(outputs,labels)\n",
    "        acc = self.binary_acc(labels, outputs)\n",
    "        predicted_mask = outputs > 0.5\n",
    "        #iou = iou_pytorch(predicted_mask.byte(), labels.squeeze(1).byte()).mean()\n",
    "        iou=miou(outputs,labels)\n",
    "        \n",
    "        self.log(\"acc\",acc,prog_bar=True)\n",
    "        self.log(\"iou\",iou,prog_bar=True)\n",
    "        return {'loss': loss, 'acc': acc,'iou':iou}\n",
    "\n",
    "    def training_epoch_end(self, outputs):#一轮数据训练结束时的操作。主要针对于本轮所有training_step的输出\n",
    "        self.epoch += 1        \n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc  = torch.stack([x['acc'] for x in outputs]).mean()\n",
    "        avg_iou  = torch.stack([x['iou'] for x in outputs]).mean()\n",
    "        print('Training (Epoch: ' + str(self.epoch) + ')')\n",
    "        print('Loss: {:.4f}, Acc: {:.4f},iou:{:.4f}'.format(avg_loss, avg_acc,avg_iou))\n",
    "        avg_loss_numpy=avg_loss.data.cpu().numpy()\n",
    "        avg_acc_numpy=avg_acc.data.cpu().numpy()\n",
    "        avg_iou_numpy=avg_iou.data.cpu().numpy()\n",
    "        self.history[\"loss\"].append(avg_loss_numpy)\n",
    "        self.history[\"acc\"].append(avg_acc_numpy)\n",
    "        self.history[\"iou\"].append(avg_iou_numpy)\n",
    "        #logs = {'loss': avg_loss, 'acc': avg_acc}s\n",
    "        #return {'loss': avg_loss, 'acc': avg_acc, 'log': logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        inputs = torch.reshape(inputs, (self.num_batch,1,128,128,128))\n",
    "        labels = torch.reshape(labels, (self.num_batch,1,128,128,128))        \n",
    "        outputs = self(inputs)\n",
    "        loss1 = self.calc_loss(labels, outputs)\n",
    "        loss2=GDiceloss(outputs,labels)\n",
    "        loss=loss2\n",
    "        #loss=Diceloss(outputs,labels)\n",
    "        #loss=focal_tversky_loss(outputs,labels)\n",
    "        acc = self.binary_acc(labels, outputs)\n",
    "        predicted_mask = outputs > 0.5\n",
    "        #iou = iou_pytorch(predicted_mask.byte(), labels.squeeze(1).byte()).mean()\n",
    "        iou=miou(outputs,labels)\n",
    "        self.log(\"val_acc\",acc,prog_bar=True)\n",
    "        self.log(\"val_iou\",iou,prog_bar=True)\n",
    "        self.log(\"val_loss\",loss,prog_bar=True)\n",
    "        return {'val_loss': loss, 'val_acc': acc,'val_iou':iou }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc  = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "        avg_iou  = torch.stack([x['val_iou'] for x in outputs]).mean()        \n",
    "        #logs = {'val_loss': avg_loss, 'val_acc': avg_acc}\n",
    "        avg_loss_numpy=avg_loss.data.cpu().numpy()\n",
    "        avg_acc_numpy=avg_acc.data.cpu().numpy()\n",
    "        avg_iou_numpy=avg_iou.data.cpu().numpy()\n",
    "        self.history[\"val_loss\"].append(avg_loss_numpy)\n",
    "        self.history[\"val_acc\"].append(avg_acc_numpy)\n",
    "        self.history[\"val_iou\"].append(avg_iou_numpy)\n",
    "        if self.epoch > 0:\n",
    "            print('Validation (Epoch: ' + str(self.epoch) + ')')\n",
    "            print('Loss: {:.4f}, Acc: {:.4f},iou:{:.4f}'.format(avg_loss, avg_acc,avg_iou))\n",
    "        #return {'val_loss': avg_loss, 'log': logs}\n",
    "    \n",
    "    def calc_loss(self, labels, outputs):\n",
    "        # Balanced Cross-Entropy\n",
    "        count_pos = labels.sum()        # Fault\n",
    "        count_neg = (1 - labels).sum()  # Non-fault\n",
    "        beta = torch.as_tensor(count_neg / (count_neg + count_pos))\n",
    "        pos_weight = torch.where(labels==1, beta / (1 - beta), torch.ones(1).cuda())\n",
    "        loss = F.binary_cross_entropy_with_logits(outputs, labels, pos_weight=pos_weight)\n",
    "        return loss * (1 - beta)\n",
    "    \n",
    "    def binary_acc(self, labels, outputs):\n",
    "        y_pred_tag = torch.round(torch.sigmoid(outputs))\n",
    "        correct_results_sum = torch.eq(y_pred_tag, labels).sum().float()\n",
    "        acc = correct_results_sum / labels.shape.numel()\n",
    "        return acc\n",
    "\n",
    "    def data_augment(self, inputs, labels, num_batch, num_ch=1, num_aug=4, dim=(128,128,128)):\n",
    "        #num_batch=num_batch/2#多GPU训练\n",
    "        X = np.zeros([num_batch*num_aug, num_ch, *dim])\n",
    "        Y = np.zeros([num_batch*num_aug, num_ch, *dim])\n",
    "\n",
    "        for i in range(num_batch):\n",
    "            for j in range(num_aug):\n",
    "                X[num_aug*i+j,] = np.rot90(inputs[i,].cpu(),j,(0,1))\n",
    "                Y[num_aug*i+j,] = np.rot90(labels[i,].cpu(),j,(0,1))\n",
    "\n",
    "        inputs_aug = torch.from_numpy(X).float().reshape((num_batch*num_aug, num_ch, *dim))\n",
    "        labels_aug = torch.from_numpy(Y).float().reshape((num_batch*num_aug, num_ch, *dim))\n",
    "        return inputs_aug.cuda(), labels_aug.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=R2AttUNet3D(in_channels=1,out_channels=1,f_maps = [32,64,128,256])\n",
    "model=model.load_from_checkpoint(\"/data/max/3d-nets/lightning_logs/R2-unet_se/2022.5.26/ce+Gdice/epoch=45-step=16146.ckpt\")\n",
    "#model=model.load_from_checkpoint(\"/data/max/3d-nets/lightning_logs/R2-unet_se/2022.6.14/学习率8e-4_944_ce+Gdice/epoch=48-step=19648.ckpt\")\n",
    "#model=model.load_from_checkpoint(\"/data/max/3d-nets/lightning_logs/R2-unet_se/2022.5.26/学习率e-4_844_se_CE/epoch=47-step=16847.ckpt\")\n",
    "#model=model.load_from_checkpoint(\"/data/max/3d-nets/lightning_logs/R2-unet_se/2022.7.1/学习率8e-4_944_ce_v2/epoch=48-step=19648-v1.ckpt\")\n",
    "\n",
    "model=model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "%matplotlib inline\n",
    "seismPath = \"./\"\n",
    "n3,n2,n1=512,384,128\n",
    "f3 = np.load(\"/data/max/FaultNet-main/data/F3.npy\").transpose((2, 1, 0))\n",
    "#gx.tofile(\"f3.raw\")\n",
    "#gx = np.reshape(gx,(n3,n2,n1))\n",
    "gx=copy.deepcopy(f3)\n",
    "gm = np.mean(gx)\n",
    "gs = np.std(gx)\n",
    "gx = gx-gm\n",
    "gx = gx/gs\n",
    "#gx = np.transpose(gx)\n",
    "a=np.reshape(gx,(1,1,n1,n2,n3))\n",
    "#a=torch.tensor(a)\n",
    "a=torch.tensor(a)\n",
    "#a=a.half()\n",
    "model.eval()\n",
    "fp = model(a)\n",
    "fp = torch.sigmoid(fp).detach().cpu().numpy()\n",
    "fp=fp.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_img (geo_slice, result_slice):\n",
    "    hm = plt.get_cmap('bone')(geo_slice)[:, :, :-1]\n",
    "    geo_slice = plt.get_cmap('seismic')(geo_slice)[:, :, :-1]\n",
    "    logits = np.clip((result_slice[:, :, None]), a_min=0, a_max=1)\n",
    "    colormap = plt.get_cmap('jet')(logits[:, :, 0])[:, :, :-1]\n",
    "    hm = np.where(logits > 0.6, colormap, hm)\n",
    "    return geo_slice, hm\n",
    "def get_result_img_3d (fp, gx):\n",
    "    hm = np.where(fp > 0.5, fp, gx)\n",
    "    return hm\n",
    "def get_result_img_(geo_slice, result_slice):\n",
    "    hm = plt.get_cmap('bone')(geo_slice)[:, :,:,:-1]\n",
    "    geo_slice = plt.get_cmap('seismic')(geo_slice)[:, :,:,:-1]\n",
    "    logits = np.clip((result_slice[:, :,:, None]), a_min=0, a_max=1)\n",
    "    colormap = plt.get_cmap('jet')(logits[:, :,:, 0])[:, :, :,:-1]\n",
    "    hm = np.where(logits > 0.5, colormap, hm)\n",
    "    return geo_slice, hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / _range\n",
    "gx = normalization(gx)\n",
    "k1,k2,k3 =88,95,32\n",
    "tline_slice = gx[k1,:,:]\n",
    "xline_slice = gx[:,:,k3]\n",
    "#print(xline_slice.shape)\n",
    "iline_slice = gx[:,k2,:]                                                            \n",
    "tline_result = fp[k1,:,:]\n",
    "xline_result = fp[:,:,k3]\n",
    "iline_result = fp[:,k2,:]\n",
    "tline_slice,tline_result = get_result_img(tline_slice,tline_result)\n",
    "iline_slice,iline_result = get_result_img(iline_slice,iline_result)\n",
    "xline_slice,xline_result = get_result_img(xline_slice,xline_result)\n",
    "tline = np.concatenate((tline_slice,tline_result),1)\n",
    "iline = np.concatenate((iline_slice,iline_result),1)\n",
    "xline = np.concatenate((xline_slice,xline_result),1)\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.imshow(tline,interpolation='bilinear'\n",
    ",aspect='auto')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28319681f7f78c9610bd67f2e4825a113d9d1be561f4d0d85c63d2b76cca0051"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
